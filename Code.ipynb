{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5664fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf716c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bcde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from time import sleep\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(r\"C:\\Users\\Sandeep Aggarwal\\Desktop\\haarcascade_frontalface_default.xml\")\n",
    "classifier =load_model(r\"C:\\Users\\Sandeep Aggarwal\\Desktop\\model.h5\")\n",
    "\n",
    "emotion_labels = ['Angry','Disgust','Fear','Happy','Neutral', 'Sad', 'Surprise']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    labels = []\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "\n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi = roi_gray.astype('float')/255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis=0)\n",
    "\n",
    "            prediction = classifier.predict(roi)[0]\n",
    "            label=emotion_labels[prediction.argmax()]\n",
    "            label_position = (x,y)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "        else:\n",
    "            cv2.putText(frame,'No Faces',(30,80),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    cv2.imshow('Emotion Detector',frame)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f22341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import multiprocessing\n",
    "import os\n",
    "import threading\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend\n",
    "from keras.utils import data_utils\n",
    "from keras.utils import image_utils\n",
    "from keras.utils import io_utils\n",
    "\n",
    "# isort: off\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    from scipy import linalg  # noqa: F401\n",
    "    from scipy import ndimage  # noqa: F401\n",
    "except ImportError:\n",
    "    pass\n",
    "try:\n",
    "    from PIL import ImageEnhance\n",
    "except ImportError:\n",
    "    ImageEnhance = None\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.Iterator\")\n",
    "class Iterator(data_utils.Sequence):\n",
    "\n",
    "\n",
    "    white_list_formats = (\"png\", \"jpg\", \"jpeg\", \"bmp\", \"ppm\", \"tif\", \"tiff\")\n",
    "\n",
    "    def __init__(self, n, batch_size, shuffle, seed):\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_index = 0\n",
    "        self.total_batches_seen = 0\n",
    "        self.lock = threading.Lock()\n",
    "        self.index_array = None\n",
    "        self.index_generator = self._flow_index()\n",
    "\n",
    "    def _set_index_array(self):\n",
    "        self.index_array = np.arange(self.n)\n",
    "        if self.shuffle:\n",
    "            self.index_array = np.random.permutation(self.n)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise ValueError(\n",
    "                \"Asked to retrieve element {idx}, \"\n",
    "                \"but the Sequence \"\n",
    "                \"has length {length}\".format(idx=idx, length=len(self))\n",
    "            )\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed + self.total_batches_seen)\n",
    "        self.total_batches_seen += 1\n",
    "        if self.index_array is None:\n",
    "            self._set_index_array()\n",
    "        index_array = self.index_array[\n",
    "            self.batch_size * idx : self.batch_size * (idx + 1)\n",
    "        ]\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.n + self.batch_size - 1) // self.batch_size  # round up\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self._set_index_array()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "\n",
    "    def _flow_index(self):\n",
    "        # Ensure self.batch_index is 0.\n",
    "        self.reset()\n",
    "        while 1:\n",
    "            if self.seed is not None:\n",
    "                np.random.seed(self.seed + self.total_batches_seen)\n",
    "            if self.batch_index == 0:\n",
    "                self._set_index_array()\n",
    "\n",
    "            if self.n == 0:\n",
    "                # Avoiding modulo by zero error\n",
    "                current_index = 0\n",
    "            else:\n",
    "                current_index = (self.batch_index * self.batch_size) % self.n\n",
    "            if self.n > current_index + self.batch_size:\n",
    "                self.batch_index += 1\n",
    "            else:\n",
    "                self.batch_index = 0\n",
    "            self.total_batches_seen += 1\n",
    "            yield self.index_array[\n",
    "                current_index : current_index + self.batch_size\n",
    "            ]\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Needed if we want to do something like:\n",
    "        # for x, y in data_gen.flow(...):\n",
    "        return self\n",
    "\n",
    "    def __next__(self, *args, **kwargs):\n",
    "        return self.next(*args, **kwargs)\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "\n",
    "        Returns:\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        return self._get_batches_of_transformed_samples(index_array)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "             raise NotImplementedError\n",
    "\n",
    "def _iter_valid_files(directory, white_list_formats, follow_links):\n",
    "    \n",
    "\n",
    "    def _recursive_list(subpath):\n",
    "        return sorted(\n",
    "            os.walk(subpath, followlinks=follow_links), key=lambda x: x[0]\n",
    "        )\n",
    "\n",
    "    for root, _, files in _recursive_list(directory):\n",
    "        for fname in sorted(files):\n",
    "            if fname.lower().endswith(\".tiff\"):\n",
    "                warnings.warn(\n",
    "                    'Using \".tiff\" files with multiple bands '\n",
    "                    \"will cause distortion. Please verify your output.\"\n",
    "                )\n",
    "            if fname.lower().endswith(white_list_formats):\n",
    "                yield root, fname\n",
    "\n",
    "\n",
    "def _list_valid_filenames_in_directory(\n",
    "    directory, white_list_formats, split, class_indices, follow_links\n",
    "):\n",
    "  \n",
    "    dirname = os.path.basename(directory)\n",
    "    if split:\n",
    "        all_files = list(\n",
    "            _iter_valid_files(directory, white_list_formats, follow_links)\n",
    "        )\n",
    "        num_files = len(all_files)\n",
    "        start, stop = int(split[0] * num_files), int(split[1] * num_files)\n",
    "        valid_files = all_files[start:stop]\n",
    "    else:\n",
    "        valid_files = _iter_valid_files(\n",
    "            directory, white_list_formats, follow_links\n",
    "        )\n",
    "    classes = []\n",
    "    filenames = []\n",
    "    for root, fname in valid_files:\n",
    "        classes.append(class_indices[dirname])\n",
    "        absolute_path = os.path.join(root, fname)\n",
    "        relative_path = os.path.join(\n",
    "            dirname, os.path.relpath(absolute_path, directory)\n",
    "        )\n",
    "        filenames.append(relative_path)\n",
    "\n",
    "    return classes, filenames\n",
    "\n",
    "\n",
    "class BatchFromFilesMixin:\n",
    "    \"\"\"Adds methods related to getting batches from filenames.\n",
    "\n",
    "    It includes the logic to transform image files to batches.\n",
    "    \"\"\"\n",
    "\n",
    "    def set_processing_attrs(\n",
    "        self,\n",
    "        image_data_generator,\n",
    "        target_size,\n",
    "        color_mode,\n",
    "        data_format,\n",
    "        save_to_dir,\n",
    "        save_prefix,\n",
    "        save_format,\n",
    "        subset,\n",
    "        interpolation,\n",
    "        keep_aspect_ratio,\n",
    "    ):\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        self.keep_aspect_ratio = keep_aspect_ratio\n",
    "        if color_mode not in {\"rgb\", \"rgba\", \"grayscale\"}:\n",
    "            raise ValueError(\n",
    "                \"Invalid color mode:\",\n",
    "                color_mode,\n",
    "                '; expected \"rgb\", \"rgba\", or \"grayscale\".',\n",
    "            )\n",
    "        self.color_mode = color_mode\n",
    "        self.data_format = data_format\n",
    "        if self.color_mode == \"rgba\":\n",
    "            if self.data_format == \"channels_last\":\n",
    "                self.image_shape = self.target_size + (4,)\n",
    "            else:\n",
    "                self.image_shape = (4,) + self.target_size\n",
    "        elif self.color_mode == \"rgb\":\n",
    "            if self.data_format == \"channels_last\":\n",
    "                self.image_shape = self.target_size + (3,)\n",
    "            else:\n",
    "                self.image_shape = (3,) + self.target_size\n",
    "        else:\n",
    "            if self.data_format == \"channels_last\":\n",
    "                self.image_shape = self.target_size + (1,)\n",
    "            else:\n",
    "                self.image_shape = (1,) + self.target_size\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "        self.interpolation = interpolation\n",
    "        if subset is not None:\n",
    "            validation_split = self.image_data_generator._validation_split\n",
    "            if subset == \"validation\":\n",
    "                split = (0, validation_split)\n",
    "            elif subset == \"training\":\n",
    "                split = (validation_split, 1)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Invalid subset name: %s;\"\n",
    "                    'expected \"training\" or \"validation\"' % (subset,)\n",
    "                )\n",
    "        else:\n",
    "            split = None\n",
    "        self.split = split\n",
    "        self.subset = subset\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "      \n",
    "        batch_x = np.zeros(\n",
    "            (len(index_array),) + self.image_shape, dtype=self.dtype\n",
    "        )\n",
    "        # build batch of image data\n",
    "        # self.filepaths is dynamic, is better to call it once outside the loop\n",
    "        filepaths = self.filepaths\n",
    "        for i, j in enumerate(index_array):\n",
    "            img = image_utils.load_img(\n",
    "                filepaths[j],\n",
    "                color_mode=self.color_mode,\n",
    "                target_size=self.target_size,\n",
    "                interpolation=self.interpolation,\n",
    "                keep_aspect_ratio=self.keep_aspect_ratio,\n",
    "            )\n",
    "            x = image_utils.img_to_array(img, data_format=self.data_format)\n",
    "            # Pillow images should be closed after `load_img`,\n",
    "            # but not PIL images.\n",
    "            if hasattr(img, \"close\"):\n",
    "                img.close()\n",
    "            if self.image_data_generator:\n",
    "                params = self.image_data_generator.get_random_transform(x.shape)\n",
    "                x = self.image_data_generator.apply_transform(x, params)\n",
    "                x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        # optionally save augmented images to disk for debugging purposes\n",
    "        if self.save_to_dir:\n",
    "            for i, j in enumerate(index_array):\n",
    "                img = image_utils.array_to_img(\n",
    "                    batch_x[i], self.data_format, scale=True\n",
    "                )\n",
    "                fname = \"{prefix}_{index}_{hash}.{format}\".format(\n",
    "                    prefix=self.save_prefix,\n",
    "                    index=j,\n",
    "                    hash=np.random.randint(1e7),\n",
    "                    format=self.save_format,\n",
    "                )\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        # build batch of labels\n",
    "        if self.class_mode == \"input\":\n",
    "            batch_y = batch_x.copy()\n",
    "        elif self.class_mode in {\"binary\", \"sparse\"}:\n",
    "            batch_y = np.empty(len(batch_x), dtype=self.dtype)\n",
    "            for i, n_observation in enumerate(index_array):\n",
    "                batch_y[i] = self.classes[n_observation]\n",
    "        elif self.class_mode == \"categorical\":\n",
    "            batch_y = np.zeros(\n",
    "                (len(batch_x), len(self.class_indices)), dtype=self.dtype\n",
    "            )\n",
    "            for i, n_observation in enumerate(index_array):\n",
    "                batch_y[i, self.classes[n_observation]] = 1.0\n",
    "        elif self.class_mode == \"multi_output\":\n",
    "            batch_y = [output[index_array] for output in self.labels]\n",
    "        elif self.class_mode == \"raw\":\n",
    "            batch_y = self.labels[index_array]\n",
    "        else:\n",
    "            return batch_x\n",
    "        if self.sample_weight is None:\n",
    "            return batch_x, batch_y\n",
    "        else:\n",
    "            return batch_x, batch_y, self.sample_weight[index_array]\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        \"\"\"List of absolute paths to image files.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"`filepaths` property method has not \"\n",
    "            \"been implemented in {}.\".format(type(self).__name__)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        \"\"\"Class labels of every observation.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"`labels` property method has not been implemented in {}.\".format(\n",
    "                type(self).__name__\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def sample_weight(self):\n",
    "        raise NotImplementedError(\n",
    "            \"`sample_weight` property method has not \"\n",
    "            \"been implemented in {}.\".format(type(self).__name__)\n",
    "        )\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.DirectoryIterator\")\n",
    "class DirectoryIterator(BatchFromFilesMixin, Iterator):\n",
    "  \n",
    "    \n",
    "\n",
    "    allowed_class_modes = {\"categorical\", \"binary\", \"sparse\", \"input\", None}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        directory,\n",
    "        image_data_generator,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        data_format=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        follow_links=False,\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        keep_aspect_ratio=False,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        if data_format is None:\n",
    "            data_format = backend.image_data_format()\n",
    "        if dtype is None:\n",
    "            dtype = backend.floatx()\n",
    "        super().set_processing_attrs(\n",
    "            image_data_generator,\n",
    "            target_size,\n",
    "            color_mode,\n",
    "            data_format,\n",
    "            save_to_dir,\n",
    "            save_prefix,\n",
    "            save_format,\n",
    "            subset,\n",
    "            interpolation,\n",
    "            keep_aspect_ratio,\n",
    "        )\n",
    "        self.directory = directory\n",
    "        self.classes = classes\n",
    "        if class_mode not in self.allowed_class_modes:\n",
    "            raise ValueError(\n",
    "                \"Invalid class_mode: {}; expected one of: {}\".format(\n",
    "                    class_mode, self.allowed_class_modes\n",
    "                )\n",
    "            )\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        # First, count the number of samples and classes.\n",
    "        self.samples = 0\n",
    "\n",
    "        if not classes:\n",
    "            classes = []\n",
    "            for subdir in sorted(os.listdir(directory)):\n",
    "                if os.path.isdir(os.path.join(directory, subdir)):\n",
    "                    classes.append(subdir)\n",
    "        self.num_classes = len(classes)\n",
    "        self.class_indices = dict(zip(classes, range(len(classes))))\n",
    "\n",
    "        pool = multiprocessing.pool.ThreadPool()\n",
    "\n",
    "        # Second, build an index of the images\n",
    "        # in the different class subfolders.\n",
    "        results = []\n",
    "        self.filenames = []\n",
    "        i = 0\n",
    "        for dirpath in (os.path.join(directory, subdir) for subdir in classes):\n",
    "            results.append(\n",
    "                pool.apply_async(\n",
    "                    _list_valid_filenames_in_directory,\n",
    "                    (\n",
    "                        dirpath,\n",
    "                        self.white_list_formats,\n",
    "                        self.split,\n",
    "                        self.class_indices,\n",
    "                        follow_links,\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "        classes_list = []\n",
    "        for res in results:\n",
    "            classes, filenames = res.get()\n",
    "            classes_list.append(classes)\n",
    "            self.filenames += filenames\n",
    "        self.samples = len(self.filenames)\n",
    "        self.classes = np.zeros((self.samples,), dtype=\"int32\")\n",
    "        for classes in classes_list:\n",
    "            self.classes[i : i + len(classes)] = classes\n",
    "            i += len(classes)\n",
    "\n",
    "        io_utils.print_msg(\n",
    "            f\"Found {self.samples} images belonging to \"\n",
    "            f\"{self.num_classes} classes.\"\n",
    "        )\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        self._filepaths = [\n",
    "            os.path.join(self.directory, fname) for fname in self.filenames\n",
    "        ]\n",
    "        super().__init__(self.samples, batch_size, shuffle, seed)\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        return self._filepaths\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self.classes\n",
    "\n",
    "    @property  # mixin needs this property to work\n",
    "    def sample_weight(self):\n",
    "        # no sample weights will be returned\n",
    "        return None\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.NumpyArrayIterator\")\n",
    "class NumpyArrayIterator(Iterator):\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x,\n",
    "        y,\n",
    "        image_data_generator,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        sample_weight=None,\n",
    "        seed=None,\n",
    "        data_format=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        ignore_class_split=False,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        if data_format is None:\n",
    "            data_format = backend.image_data_format()\n",
    "        if dtype is None:\n",
    "            dtype = backend.floatx()\n",
    "        self.dtype = dtype\n",
    "        if isinstance(x, tuple) or isinstance(x, list):\n",
    "            if not isinstance(x[1], list):\n",
    "                x_misc = [np.asarray(x[1])]\n",
    "            else:\n",
    "                x_misc = [np.asarray(xx) for xx in x[1]]\n",
    "            x = x[0]\n",
    "            for xx in x_misc:\n",
    "                if len(x) != len(xx):\n",
    "                    raise ValueError(\n",
    "                        \"All of the arrays in `x` \"\n",
    "                        \"should have the same length. \"\n",
    "                        \"Found a pair with: len(x[0]) = %s, len(x[?]) = %s\"\n",
    "                        % (len(x), len(xx))\n",
    "                    )\n",
    "        else:\n",
    "            x_misc = []\n",
    "\n",
    "        if y is not None and len(x) != len(y):\n",
    "            raise ValueError(\n",
    "                \"`x` (images tensor) and `y` (labels) \"\n",
    "                \"should have the same length. \"\n",
    "                \"Found: x.shape = %s, y.shape = %s\"\n",
    "                % (np.asarray(x).shape, np.asarray(y).shape)\n",
    "            )\n",
    "        if sample_weight is not None and len(x) != len(sample_weight):\n",
    "            raise ValueError(\n",
    "                \"`x` (images tensor) and `sample_weight` \"\n",
    "                \"should have the same length. \"\n",
    "                \"Found: x.shape = %s, sample_weight.shape = %s\"\n",
    "                % (np.asarray(x).shape, np.asarray(sample_weight).shape)\n",
    "            )\n",
    "        if subset is not None:\n",
    "            if subset not in {\"training\", \"validation\"}:\n",
    "                raise ValueError(\n",
    "                    \"Invalid subset name:\",\n",
    "                    subset,\n",
    "                    '; expected \"training\" or \"validation\".',\n",
    "                )\n",
    "            split_idx = int(len(x) * image_data_generator._validation_split)\n",
    "\n",
    "            if (\n",
    "                y is not None\n",
    "                and not ignore_class_split\n",
    "                and not np.array_equal(\n",
    "                    np.unique(y[:split_idx]), np.unique(y[split_idx:])\n",
    "                )\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"Training and validation subsets \"\n",
    "                    \"have different number of classes after \"\n",
    "                    \"the split. If your numpy arrays are \"\n",
    "                    \"sorted by the label, you might want \"\n",
    "                    \"to shuffle them.\"\n",
    "                )\n",
    "\n",
    "            if subset == \"validation\":\n",
    "                x = x[:split_idx]\n",
    "                x_misc = [np.asarray(xx[:split_idx]) for xx in x_misc]\n",
    "                if y is not None:\n",
    "                    y = y[:split_idx]\n",
    "            else:\n",
    "                x = x[split_idx:]\n",
    "                x_misc = [np.asarray(xx[split_idx:]) for xx in x_misc]\n",
    "                if y is not None:\n",
    "                    y = y[split_idx:]\n",
    "\n",
    "        self.x = np.asarray(x, dtype=self.dtype)\n",
    "        self.x_misc = x_misc\n",
    "        if self.x.ndim != 4:\n",
    "            raise ValueError(\n",
    "                \"Input data in `NumpyArrayIterator` \"\n",
    "                \"should have rank 4. You passed an array \"\n",
    "                \"with shape\",\n",
    "                self.x.shape,\n",
    "            )\n",
    "        channels_axis = 3 if data_format == \"channels_last\" else 1\n",
    "        if self.x.shape[channels_axis] not in {1, 3, 4}:\n",
    "            warnings.warn(\n",
    "                \"NumpyArrayIterator is set to use the \"\n",
    "                'data format convention \"' + data_format + '\" '\n",
    "                \"(channels on axis \"\n",
    "                + str(channels_axis)\n",
    "                + \"), i.e. expected either 1, 3, or 4 \"\n",
    "                \"channels on axis \" + str(channels_axis) + \". \"\n",
    "                \"However, it was passed an array with shape \"\n",
    "                + str(self.x.shape)\n",
    "                + \" (\"\n",
    "                + str(self.x.shape[channels_axis])\n",
    "                + \" channels).\"\n",
    "            )\n",
    "        if y is not None:\n",
    "            self.y = np.asarray(y)\n",
    "        else:\n",
    "            self.y = None\n",
    "        if sample_weight is not None:\n",
    "            self.sample_weight = np.asarray(sample_weight)\n",
    "        else:\n",
    "            self.sample_weight = None\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.data_format = data_format\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "        super().__init__(x.shape[0], batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        batch_x = np.zeros(\n",
    "            tuple([len(index_array)] + list(self.x.shape)[1:]), dtype=self.dtype\n",
    "        )\n",
    "        for i, j in enumerate(index_array):\n",
    "            x = self.x[j]\n",
    "            params = self.image_data_generator.get_random_transform(x.shape)\n",
    "            x = self.image_data_generator.apply_transform(\n",
    "                x.astype(self.dtype), params\n",
    "            )\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "\n",
    "        if self.save_to_dir:\n",
    "            for i, j in enumerate(index_array):\n",
    "                img = image_utils.array_to_img(\n",
    "                    batch_x[i], self.data_format, scale=True\n",
    "                )\n",
    "                fname = \"{prefix}_{index}_{hash}.{format}\".format(\n",
    "                    prefix=self.save_prefix,\n",
    "                    index=j,\n",
    "                    hash=np.random.randint(1e4),\n",
    "                    format=self.save_format,\n",
    "                )\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        batch_x_miscs = [xx[index_array] for xx in self.x_misc]\n",
    "        output = (batch_x if not batch_x_miscs else [batch_x] + batch_x_miscs,)\n",
    "        if self.y is None:\n",
    "            return output[0]\n",
    "        output += (self.y[index_array],)\n",
    "        if self.sample_weight is not None:\n",
    "            output += (self.sample_weight[index_array],)\n",
    "        return output\n",
    "\n",
    "\n",
    "def validate_filename(filename, white_list_formats):\n",
    "\n",
    "    return filename.lower().endswith(white_list_formats) and os.path.isfile(\n",
    "        filename\n",
    "    )\n",
    "\n",
    "\n",
    "class DataFrameIterator(BatchFromFilesMixin, Iterator):\n",
    "       \n",
    "\n",
    "    allowed_class_modes = {\n",
    "        \"binary\",\n",
    "        \"categorical\",\n",
    "        \"input\",\n",
    "        \"multi_output\",\n",
    "        \"raw\",\n",
    "        \"sparse\",\n",
    "        None,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe,\n",
    "        directory=None,\n",
    "        image_data_generator=None,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        weight_col=None,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        data_format=\"channels_last\",\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        keep_aspect_ratio=False,\n",
    "        dtype=\"float32\",\n",
    "        validate_filenames=True,\n",
    "    ):\n",
    "        super().set_processing_attrs(\n",
    "            image_data_generator,\n",
    "            target_size,\n",
    "            color_mode,\n",
    "            data_format,\n",
    "            save_to_dir,\n",
    "            save_prefix,\n",
    "            save_format,\n",
    "            subset,\n",
    "            interpolation,\n",
    "            keep_aspect_ratio,\n",
    "        )\n",
    "        df = dataframe.copy()\n",
    "        self.directory = directory or \"\"\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        # check that inputs match the required class_mode\n",
    "        self._check_params(df, x_col, y_col, weight_col, classes)\n",
    "        if (\n",
    "            validate_filenames\n",
    "        ):  # check which image files are valid and keep them\n",
    "            df = self._filter_valid_filepaths(df, x_col)\n",
    "        if class_mode not in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            df, classes = self._filter_classes(df, y_col, classes)\n",
    "            num_classes = len(classes)\n",
    "            # build an index of all the unique classes\n",
    "            self.class_indices = dict(zip(classes, range(len(classes))))\n",
    "        # retrieve only training or validation set\n",
    "        if self.split:\n",
    "            num_files = len(df)\n",
    "            start = int(self.split[0] * num_files)\n",
    "            stop = int(self.split[1] * num_files)\n",
    "            df = df.iloc[start:stop, :]\n",
    "        # get labels for each observation\n",
    "        if class_mode not in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            self.classes = self.get_classes(df, y_col)\n",
    "        self.filenames = df[x_col].tolist()\n",
    "        self._sample_weight = df[weight_col].values if weight_col else None\n",
    "\n",
    "        if class_mode == \"multi_output\":\n",
    "            self._targets = [np.array(df[col].tolist()) for col in y_col]\n",
    "        if class_mode == \"raw\":\n",
    "            self._targets = df[y_col].values\n",
    "        self.samples = len(self.filenames)\n",
    "        validated_string = (\n",
    "            \"validated\" if validate_filenames else \"non-validated\"\n",
    "        )\n",
    "        if class_mode in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            io_utils.print_msg(\n",
    "                f\"Found {self.samples} {validated_string} image filenames.\"\n",
    "            )\n",
    "        else:\n",
    "            io_utils.print_msg(\n",
    "                f\"Found {self.samples} {validated_string} image filenames \"\n",
    "                f\"belonging to {num_classes} classes.\"\n",
    "            )\n",
    "        self._filepaths = [\n",
    "            os.path.join(self.directory, fname) for fname in self.filenames\n",
    "        ]\n",
    "        super().__init__(self.samples, batch_size, shuffle, seed)\n",
    "\n",
    "    def _check_params(self, df, x_col, y_col, weight_col, classes):\n",
    "        # check class mode is one of the currently supported\n",
    "        if self.class_mode not in self.allowed_class_modes:\n",
    "            raise ValueError(\n",
    "                \"Invalid class_mode: {}; expected one of: {}\".format(\n",
    "                    self.class_mode, self.allowed_class_modes\n",
    "                )\n",
    "            )\n",
    "        # check that y_col has several column names if class_mode is\n",
    "        # multi_output\n",
    "        if (self.class_mode == \"multi_output\") and not isinstance(y_col, list):\n",
    "            raise TypeError(\n",
    "                'If class_mode=\"{}\", y_col must be a list. Received {}.'.format(\n",
    "                    self.class_mode, type(y_col).__name__\n",
    "                )\n",
    "            )\n",
    "        # check that filenames/filepaths column values are all strings\n",
    "        if not all(df[x_col].apply(lambda x: isinstance(x, str))):\n",
    "            raise TypeError(\n",
    "                \"All values in column x_col={} must be strings.\".format(x_col)\n",
    "            )\n",
    "        # check labels are string if class_mode is binary or sparse\n",
    "        if self.class_mode in {\"binary\", \"sparse\"}:\n",
    "            if not all(df[y_col].apply(lambda x: isinstance(x, str))):\n",
    "                raise TypeError(\n",
    "                    'If class_mode=\"{}\", y_col=\"{}\" column '\n",
    "                    \"values must be strings.\".format(self.class_mode, y_col)\n",
    "                )\n",
    "        # check that if binary there are only 2 different classes\n",
    "        if self.class_mode == \"binary\":\n",
    "            if classes:\n",
    "                classes = set(classes)\n",
    "                if len(classes) != 2:\n",
    "                    raise ValueError(\n",
    "                        'If class_mode=\"binary\" there must be 2 '\n",
    "                        \"classes. {} class/es were given.\".format(len(classes))\n",
    "                    )\n",
    "            elif df[y_col].nunique() != 2:\n",
    "                raise ValueError(\n",
    "                    'If class_mode=\"binary\" there must be 2 classes. '\n",
    "                    \"Found {} classes.\".format(df[y_col].nunique())\n",
    "                )\n",
    "        # check values are string, list or tuple if class_mode is categorical\n",
    "        if self.class_mode == \"categorical\":\n",
    "            types = (str, list, tuple)\n",
    "            if not all(df[y_col].apply(lambda x: isinstance(x, types))):\n",
    "                raise TypeError(\n",
    "                    'If class_mode=\"{}\", y_col=\"{}\" column '\n",
    "                    \"values must be type string, list or tuple.\".format(\n",
    "                        self.class_mode, y_col\n",
    "                    )\n",
    "                )\n",
    "        # raise warning if classes are given but will be unused\n",
    "        if classes and self.class_mode in {\n",
    "            \"input\",\n",
    "            \"multi_output\",\n",
    "            \"raw\",\n",
    "            None,\n",
    "        }:\n",
    "            warnings.warn(\n",
    "                '`classes` will be ignored given the class_mode=\"{}\"'.format(\n",
    "                    self.class_mode\n",
    "                )\n",
    "            )\n",
    "        # check that if weight column that the values are numerical\n",
    "        if weight_col and not issubclass(df[weight_col].dtype.type, np.number):\n",
    "            raise TypeError(\n",
    "                \"Column weight_col={} must be numeric.\".format(weight_col)\n",
    "            )\n",
    "\n",
    "    def get_classes(self, df, y_col):\n",
    "        labels = []\n",
    "        for label in df[y_col]:\n",
    "            if isinstance(label, (list, tuple)):\n",
    "                labels.append([self.class_indices[lbl] for lbl in label])\n",
    "            else:\n",
    "                labels.append(self.class_indices[label])\n",
    "        return labels\n",
    "\n",
    "    @staticmethod\n",
    "    def _filter_classes(df, y_col, classes):\n",
    "        df = df.copy()\n",
    "\n",
    "        def remove_classes(labels, classes):\n",
    "            if isinstance(labels, (list, tuple)):\n",
    "                labels = [cls for cls in labels if cls in classes]\n",
    "                return labels or None\n",
    "            elif isinstance(labels, str):\n",
    "                return labels if labels in classes else None\n",
    "            else:\n",
    "                raise TypeError(\n",
    "                    \"Expect string, list or tuple \"\n",
    "                    \"but found {} in {} column \".format(type(labels), y_col)\n",
    "                )\n",
    "\n",
    "        if classes:\n",
    "            # prepare for membership lookup\n",
    "            classes = list(collections.OrderedDict.fromkeys(classes).keys())\n",
    "            df[y_col] = df[y_col].apply(lambda x: remove_classes(x, classes))\n",
    "        else:\n",
    "            classes = set()\n",
    "            for v in df[y_col]:\n",
    "                if isinstance(v, (list, tuple)):\n",
    "                    classes.update(v)\n",
    "                else:\n",
    "                    classes.add(v)\n",
    "            classes = sorted(classes)\n",
    "        return df.dropna(subset=[y_col]), classes\n",
    "\n",
    "    def _filter_valid_filepaths(self, df, x_col):\n",
    "        \n",
    "        filepaths = df[x_col].map(\n",
    "            lambda fname: os.path.join(self.directory, fname)\n",
    "        )\n",
    "        mask = filepaths.apply(\n",
    "            validate_filename, args=(self.white_list_formats,)\n",
    "        )\n",
    "        n_invalid = (~mask).sum()\n",
    "        if n_invalid:\n",
    "            warnings.warn(\n",
    "                'Found {} invalid image filename(s) in x_col=\"{}\". '\n",
    "                \"These filename(s) will be ignored.\".format(n_invalid, x_col)\n",
    "            )\n",
    "        return df[mask]\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        return self._filepaths\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        if self.class_mode in {\"multi_output\", \"raw\"}:\n",
    "            return self._targets\n",
    "        else:\n",
    "            return self.classes\n",
    "\n",
    "    @property\n",
    "    def sample_weight(self):\n",
    "        return self._sample_weight\n",
    "\n",
    "\n",
    "def flip_axis(x, axis):\n",
    "    x = np.asarray(x).swapaxes(axis, 0)\n",
    "    x = x[::-1, ...]\n",
    "    x = x.swapaxes(0, axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.ImageDataGenerator\")\n",
    "class ImageDataGenerator:      \n",
    "     \n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-6,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        brightness_range=None,\n",
    "        shear_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode=\"nearest\",\n",
    "        cval=0.0,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0,\n",
    "        interpolation_order=1,\n",
    "        dtype=None,\n",
    "    ):\n",
    "        if data_format is None:\n",
    "            data_format = backend.image_data_format()\n",
    "        if dtype is None:\n",
    "            dtype = backend.floatx()\n",
    "\n",
    "        self.featurewise_center = featurewise_center\n",
    "        self.samplewise_center = samplewise_center\n",
    "        self.featurewise_std_normalization = featurewise_std_normalization\n",
    "        self.samplewise_std_normalization = samplewise_std_normalization\n",
    "        self.zca_whitening = zca_whitening\n",
    "        self.zca_epsilon = zca_epsilon\n",
    "        self.rotation_range = rotation_range\n",
    "        self.width_shift_range = width_shift_range\n",
    "        self.height_shift_range = height_shift_range\n",
    "        self.shear_range = shear_range\n",
    "        self.zoom_range = zoom_range\n",
    "        self.channel_shift_range = channel_shift_range\n",
    "        self.fill_mode = fill_mode\n",
    "        self.cval = cval\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.vertical_flip = vertical_flip\n",
    "        self.rescale = rescale\n",
    "        self.preprocessing_function = preprocessing_function\n",
    "        self.dtype = dtype\n",
    "        self.interpolation_order = interpolation_order\n",
    "\n",
    "        if data_format not in {\"channels_last\", \"channels_first\"}:\n",
    "            raise ValueError(\n",
    "                '`data_format` should be `\"channels_last\"` '\n",
    "                \"(channel after row and column) or \"\n",
    "                '`\"channels_first\"` (channel before row and column). '\n",
    "                \"Received: %s\" % data_format\n",
    "            )\n",
    "        self.data_format = data_format\n",
    "        if data_format == \"channels_first\":\n",
    "            self.channel_axis = 1\n",
    "            self.row_axis = 2\n",
    "            self.col_axis = 3\n",
    "        if data_format == \"channels_last\":\n",
    "            self.channel_axis = 3\n",
    "            self.row_axis = 1\n",
    "            self.col_axis = 2\n",
    "        if validation_split and not 0 < validation_split < 1:\n",
    "            raise ValueError(\n",
    "                \"`validation_split` must be strictly between 0 and 1. \"\n",
    "                \" Received: %s\" % validation_split\n",
    "            )\n",
    "        self._validation_split = validation_split\n",
    "\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.zca_whitening_matrix = None\n",
    "\n",
    "        if isinstance(zoom_range, (float, int)):\n",
    "            self.zoom_range = [1 - zoom_range, 1 + zoom_range]\n",
    "        elif len(zoom_range) == 2 and all(\n",
    "            isinstance(val, (float, int)) for val in zoom_range\n",
    "        ):\n",
    "            self.zoom_range = [zoom_range[0], zoom_range[1]]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`zoom_range` should be a float or \"\n",
    "                \"a tuple or list of two floats. \"\n",
    "                \"Received: %s\" % (zoom_range,)\n",
    "            )\n",
    "        if zca_whitening:\n",
    "            if not featurewise_center:\n",
    "                self.featurewise_center = True\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`zca_whitening`, which overrides \"\n",
    "                    \"setting of `featurewise_center`.\"\n",
    "                )\n",
    "            if featurewise_std_normalization:\n",
    "                self.featurewise_std_normalization = False\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`zca_whitening` \"\n",
    "                    \"which overrides setting of\"\n",
    "                    \"`featurewise_std_normalization`.\"\n",
    "                )\n",
    "        if featurewise_std_normalization:\n",
    "            if not featurewise_center:\n",
    "                self.featurewise_center = True\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`featurewise_std_normalization`, \"\n",
    "                    \"which overrides setting of \"\n",
    "                    \"`featurewise_center`.\"\n",
    "                )\n",
    "        if samplewise_std_normalization:\n",
    "            if not samplewise_center:\n",
    "                self.samplewise_center = True\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`samplewise_std_normalization`, \"\n",
    "                    \"which overrides setting of \"\n",
    "                    \"`samplewise_center`.\"\n",
    "                )\n",
    "        if brightness_range is not None:\n",
    "            if (\n",
    "                not isinstance(brightness_range, (tuple, list))\n",
    "                or len(brightness_range) != 2\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"`brightness_range should be tuple or list of two floats. \"\n",
    "                    \"Received: %s\" % (brightness_range,)\n",
    "                )\n",
    "        self.brightness_range = brightness_range\n",
    "\n",
    "    def flow(\n",
    "        self,\n",
    "        x,\n",
    "        y=None,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        sample_weight=None,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        ignore_class_split=False,\n",
    "        subset=None,\n",
    "    ):\n",
    "      \n",
    "           \n",
    "        return NumpyArrayIterator(\n",
    "            x,\n",
    "            y,\n",
    "            self,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            sample_weight=sample_weight,\n",
    "            seed=seed,\n",
    "            data_format=self.data_format,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            ignore_class_split=ignore_class_split,\n",
    "            subset=subset,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "\n",
    "    def flow_from_directory(\n",
    "        self,\n",
    "        directory,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        follow_links=False,\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        keep_aspect_ratio=False,\n",
    "    ):\n",
    "        \n",
    "        return DirectoryIterator(\n",
    "            directory,\n",
    "            self,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            keep_aspect_ratio=keep_aspect_ratio,\n",
    "            classes=classes,\n",
    "            class_mode=class_mode,\n",
    "            data_format=self.data_format,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            follow_links=follow_links,\n",
    "            subset=subset,\n",
    "            interpolation=interpolation,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "\n",
    "    def flow_from_dataframe(\n",
    "        self,\n",
    "        dataframe,\n",
    "        directory=None,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        weight_col=None,\n",
    "        target_size=(256, 256),\n",
    "        color_mode=\"rgb\",\n",
    "        classes=None,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=None,\n",
    "        save_to_dir=None,\n",
    "        save_prefix=\"\",\n",
    "        save_format=\"png\",\n",
    "        subset=None,\n",
    "        interpolation=\"nearest\",\n",
    "        validate_filenames=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "      \n",
    "           \n",
    "        if \"has_ext\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"has_ext is deprecated, filenames in the dataframe have \"\n",
    "                \"to match the exact filenames in disk.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "        if \"sort\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"sort is deprecated, batches will be created in the\"\n",
    "                \"same order than the filenames provided if shuffle\"\n",
    "                \"is set to False.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "        if class_mode == \"other\":\n",
    "            warnings.warn(\n",
    "                '`class_mode` \"other\" is deprecated, please use '\n",
    "                '`class_mode` \"raw\".',\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "            class_mode = \"raw\"\n",
    "        if \"drop_duplicates\" in kwargs:\n",
    "            warnings.warn(\n",
    "                \"drop_duplicates is deprecated, you can drop duplicates \"\n",
    "                \"by using the pandas.DataFrame.drop_duplicates method.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "\n",
    "        return DataFrameIterator(\n",
    "            dataframe,\n",
    "            directory,\n",
    "            self,\n",
    "            x_col=x_col,\n",
    "            y_col=y_col,\n",
    "            weight_col=weight_col,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            classes=classes,\n",
    "            class_mode=class_mode,\n",
    "            data_format=self.data_format,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            subset=subset,\n",
    "            interpolation=interpolation,\n",
    "            validate_filenames=validate_filenames,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "\n",
    "    def standardize(self, x):\n",
    "     \n",
    "        if self.preprocessing_function:\n",
    "            x = self.preprocessing_function(x)\n",
    "        if self.rescale:\n",
    "            x *= self.rescale\n",
    "        if self.samplewise_center:\n",
    "            x -= np.mean(x, keepdims=True)\n",
    "        if self.samplewise_std_normalization:\n",
    "            x /= np.std(x, keepdims=True) + 1e-6\n",
    "\n",
    "        if self.featurewise_center:\n",
    "            if self.mean is not None:\n",
    "                x -= self.mean\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`featurewise_center`, but it hasn't \"\n",
    "                    \"been fit on any training data. Fit it \"\n",
    "                    \"first by calling `.fit(numpy_data)`.\"\n",
    "                )\n",
    "        if self.featurewise_std_normalization:\n",
    "            if self.std is not None:\n",
    "                x /= self.std + 1e-6\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`featurewise_std_normalization`, \"\n",
    "                    \"but it hasn't \"\n",
    "                    \"been fit on any training data. Fit it \"\n",
    "                    \"first by calling `.fit(numpy_data)`.\"\n",
    "                )\n",
    "        if self.zca_whitening:\n",
    "            if self.zca_whitening_matrix is not None:\n",
    "                flat_x = x.reshape(-1, np.prod(x.shape[-3:]))\n",
    "                white_x = flat_x @ self.zca_whitening_matrix\n",
    "                x = np.reshape(white_x, x.shape)\n",
    "            else:\n",
    "                warnings.warn(\n",
    "                    \"This ImageDataGenerator specifies \"\n",
    "                    \"`zca_whitening`, but it hasn't \"\n",
    "                    \"been fit on any training data. Fit it \"\n",
    "                    \"first by calling `.fit(numpy_data)`.\"\n",
    "                )\n",
    "        return x\n",
    "\n",
    "    def get_random_transform(self, img_shape, seed=None):\n",
    "       \n",
    "        img_row_axis = self.row_axis - 1\n",
    "        img_col_axis = self.col_axis - 1\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        if self.rotation_range:\n",
    "            theta = np.random.uniform(-self.rotation_range, self.rotation_range)\n",
    "        else:\n",
    "            theta = 0\n",
    "\n",
    "        if self.height_shift_range:\n",
    "            try:  # 1-D array-like or int\n",
    "                tx = np.random.choice(self.height_shift_range)\n",
    "                tx *= np.random.choice([-1, 1])\n",
    "            except ValueError:  # floating point\n",
    "                tx = np.random.uniform(\n",
    "                    -self.height_shift_range, self.height_shift_range\n",
    "                )\n",
    "            if np.max(self.height_shift_range) < 1:\n",
    "                tx *= img_shape[img_row_axis]\n",
    "        else:\n",
    "            tx = 0\n",
    "\n",
    "        if self.width_shift_range:\n",
    "            try:  # 1-D array-like or int\n",
    "                ty = np.random.choice(self.width_shift_range)\n",
    "                ty *= np.random.choice([-1, 1])\n",
    "            except ValueError:  # floating point\n",
    "                ty = np.random.uniform(\n",
    "                    -self.width_shift_range, self.width_shift_range\n",
    "                )\n",
    "            if np.max(self.width_shift_range) < 1:\n",
    "                ty *= img_shape[img_col_axis]\n",
    "        else:\n",
    "            ty = 0\n",
    "\n",
    "        if self.shear_range:\n",
    "            shear = np.random.uniform(-self.shear_range, self.shear_range)\n",
    "        else:\n",
    "            shear = 0\n",
    "\n",
    "        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n",
    "            zx, zy = 1, 1\n",
    "        else:\n",
    "            zx, zy = np.random.uniform(\n",
    "                self.zoom_range[0], self.zoom_range[1], 2\n",
    "            )\n",
    "\n",
    "        flip_horizontal = (np.random.random() < 0.5) * self.horizontal_flip\n",
    "        flip_vertical = (np.random.random() < 0.5) * self.vertical_flip\n",
    "\n",
    "        channel_shift_intensity = None\n",
    "        if self.channel_shift_range != 0:\n",
    "            channel_shift_intensity = np.random.uniform(\n",
    "                -self.channel_shift_range, self.channel_shift_range\n",
    "            )\n",
    "\n",
    "        brightness = None\n",
    "        if self.brightness_range is not None:\n",
    "            brightness = np.random.uniform(\n",
    "                self.brightness_range[0], self.brightness_range[1]\n",
    "            )\n",
    "\n",
    "        transform_parameters = {\n",
    "            \"theta\": theta,\n",
    "            \"tx\": tx,\n",
    "            \"ty\": ty,\n",
    "            \"shear\": shear,\n",
    "            \"zx\": zx,\n",
    "            \"zy\": zy,\n",
    "            \"flip_horizontal\": flip_horizontal,\n",
    "            \"flip_vertical\": flip_vertical,\n",
    "            \"channel_shift_intensity\": channel_shift_intensity,\n",
    "            \"brightness\": brightness,\n",
    "        }\n",
    "\n",
    "        return transform_parameters\n",
    "\n",
    "    def apply_transform(self, x, transform_parameters):\n",
    "      \n",
    "        # x is a single image, so it doesn't have image number at index 0\n",
    "        img_row_axis = self.row_axis - 1\n",
    "        img_col_axis = self.col_axis - 1\n",
    "        img_channel_axis = self.channel_axis - 1\n",
    "\n",
    "        x = apply_affine_transform(\n",
    "            x,\n",
    "            transform_parameters.get(\"theta\", 0),\n",
    "            transform_parameters.get(\"tx\", 0),\n",
    "            transform_parameters.get(\"ty\", 0),\n",
    "            transform_parameters.get(\"shear\", 0),\n",
    "            transform_parameters.get(\"zx\", 1),\n",
    "            transform_parameters.get(\"zy\", 1),\n",
    "            row_axis=img_row_axis,\n",
    "            col_axis=img_col_axis,\n",
    "            channel_axis=img_channel_axis,\n",
    "            fill_mode=self.fill_mode,\n",
    "            cval=self.cval,\n",
    "            order=self.interpolation_order,\n",
    "        )\n",
    "\n",
    "        if transform_parameters.get(\"channel_shift_intensity\") is not None:\n",
    "            x = apply_channel_shift(\n",
    "                x,\n",
    "                transform_parameters[\"channel_shift_intensity\"],\n",
    "                img_channel_axis,\n",
    "            )\n",
    "\n",
    "        if transform_parameters.get(\"flip_horizontal\", False):\n",
    "            x = flip_axis(x, img_col_axis)\n",
    "\n",
    "        if transform_parameters.get(\"flip_vertical\", False):\n",
    "            x = flip_axis(x, img_row_axis)\n",
    "\n",
    "        if transform_parameters.get(\"brightness\") is not None:\n",
    "            x = apply_brightness_shift(\n",
    "                x, transform_parameters[\"brightness\"], False\n",
    "            )\n",
    "\n",
    "        return x\n",
    "\n",
    "    def random_transform(self, x, seed=None):\n",
    "        \"\"\"Applies a random transformation to an image.\n",
    "\n",
    "        Args:\n",
    "            x: 3D tensor, single image.\n",
    "            seed: Random seed.\n",
    "\n",
    "        Returns:\n",
    "            A randomly transformed version of the input (same shape).\n",
    "        \"\"\"\n",
    "        params = self.get_random_transform(x.shape, seed)\n",
    "        return self.apply_transform(x, params)\n",
    "\n",
    "    def fit(self, x, augment=False, rounds=1, seed=None):\n",
    "    \n",
    "        x = np.asarray(x, dtype=self.dtype)\n",
    "        if x.ndim != 4:\n",
    "            raise ValueError(\n",
    "                \"Input to `.fit()` should have rank 4. \"\n",
    "                \"Got array with shape: \" + str(x.shape)\n",
    "            )\n",
    "        if x.shape[self.channel_axis] not in {1, 3, 4}:\n",
    "            warnings.warn(\n",
    "                \"Expected input to be images (as Numpy array) \"\n",
    "                'following the data format convention \"'\n",
    "                + self.data_format\n",
    "                + '\" (channels on axis '\n",
    "                + str(self.channel_axis)\n",
    "                + \"), i.e. expected \"\n",
    "                \"either 1, 3 or 4 channels on axis \"\n",
    "                + str(self.channel_axis)\n",
    "                + \". \"\n",
    "                \"However, it was passed an array with shape \"\n",
    "                + str(x.shape)\n",
    "                + \" (\"\n",
    "                + str(x.shape[self.channel_axis])\n",
    "                + \" channels).\"\n",
    "            )\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        x = np.copy(x)\n",
    "        if self.rescale:\n",
    "            x *= self.rescale\n",
    "\n",
    "        if augment:\n",
    "            ax = np.zeros(\n",
    "                tuple([rounds * x.shape[0]] + list(x.shape)[1:]),\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "            for r in range(rounds):\n",
    "                for i in range(x.shape[0]):\n",
    "                    ax[i + r * x.shape[0]] = self.random_transform(x[i])\n",
    "            x = ax\n",
    "\n",
    "        if self.featurewise_center:\n",
    "            self.mean = np.mean(x, axis=(0, self.row_axis, self.col_axis))\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n",
    "            self.mean = np.reshape(self.mean, broadcast_shape)\n",
    "            x -= self.mean\n",
    "\n",
    "        if self.featurewise_std_normalization:\n",
    "            self.std = np.std(x, axis=(0, self.row_axis, self.col_axis))\n",
    "            broadcast_shape = [1, 1, 1]\n",
    "            broadcast_shape[self.channel_axis - 1] = x.shape[self.channel_axis]\n",
    "            self.std = np.reshape(self.std, broadcast_shape)\n",
    "            x /= self.std + 1e-6\n",
    "\n",
    "        if self.zca_whitening:\n",
    "            n = len(x)\n",
    "            flat_x = np.reshape(x, (n, -1))\n",
    "\n",
    "            u, s, _ = np.linalg.svd(flat_x.T, full_matrices=False)\n",
    "            s_inv = np.sqrt(n) / (s + self.zca_epsilon)\n",
    "            self.zca_whitening_matrix = (u * s_inv).dot(u.T)\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_rotation\")\n",
    "def random_rotation(\n",
    "    x,\n",
    "    rg,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "    \n",
    "    theta = np.random.uniform(-rg, rg)\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        theta=theta,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_shift\")\n",
    "def random_shift(\n",
    "    x,\n",
    "    wrg,\n",
    "    hrg,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "    \n",
    "    h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "    tx = np.random.uniform(-hrg, hrg) * h\n",
    "    ty = np.random.uniform(-wrg, wrg) * w\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        tx=tx,\n",
    "        ty=ty,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_shear\")\n",
    "def random_shear(\n",
    "    x,\n",
    "    intensity,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "    \n",
    "    shear = np.random.uniform(-intensity, intensity)\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        shear=shear,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_zoom\")\n",
    "def random_zoom(\n",
    "    x,\n",
    "    zoom_range,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    interpolation_order=1,\n",
    "):\n",
    "  \n",
    "    if len(zoom_range) != 2:\n",
    "        raise ValueError(\n",
    "            \"`zoom_range` should be a tuple or list of two\"\n",
    "            \" floats. Received: %s\" % (zoom_range,)\n",
    "        )\n",
    "\n",
    "    if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "        zx, zy = 1, 1\n",
    "    else:\n",
    "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
    "    x = apply_affine_transform(\n",
    "        x,\n",
    "        zx=zx,\n",
    "        zy=zy,\n",
    "        row_axis=row_axis,\n",
    "        col_axis=col_axis,\n",
    "        channel_axis=channel_axis,\n",
    "        fill_mode=fill_mode,\n",
    "        cval=cval,\n",
    "        order=interpolation_order,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.apply_channel_shift\")\n",
    "def apply_channel_shift(x, intensity, channel_axis=0):\n",
    "    \"\"\"Performs a channel shift.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor. Must be 3D.\n",
    "        intensity: Transformation intensity.\n",
    "        channel_axis: Index of axis for channels in the input tensor.\n",
    "\n",
    "    Returns:\n",
    "        Numpy image tensor.\n",
    "    \"\"\"\n",
    "    x = np.rollaxis(x, channel_axis, 0)\n",
    "    min_x, max_x = np.min(x), np.max(x)\n",
    "    channel_images = [\n",
    "        np.clip(x_channel + intensity, min_x, max_x) for x_channel in x\n",
    "    ]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_channel_shift\")\n",
    "def random_channel_shift(x, intensity_range, channel_axis=0):\n",
    " \n",
    "    intensity = np.random.uniform(-intensity_range, intensity_range)\n",
    "    return apply_channel_shift(x, intensity, channel_axis=channel_axis)\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.apply_brightness_shift\")\n",
    "def apply_brightness_shift(x, brightness, scale=True):\n",
    "  \n",
    "    if ImageEnhance is None:\n",
    "        raise ImportError(\n",
    "            \"Using brightness shifts requires PIL. \" \"Install PIL or Pillow.\"\n",
    "        )\n",
    "    x_min, x_max = np.min(x), np.max(x)\n",
    "    local_scale = (x_min < 0) or (x_max > 255)\n",
    "    x = image_utils.array_to_img(x, scale=local_scale or scale)\n",
    "    x = imgenhancer_Brightness = ImageEnhance.Brightness(x)\n",
    "    x = imgenhancer_Brightness.enhance(brightness)\n",
    "    x = image_utils.img_to_array(x)\n",
    "    if not scale and local_scale:\n",
    "        x = x / 255 * (x_max - x_min) + x_min\n",
    "    return x\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.random_brightness\")\n",
    "def random_brightness(x, brightness_range, scale=True):\n",
    "\n",
    "    if len(brightness_range) != 2:\n",
    "        raise ValueError(\n",
    "            \"`brightness_range should be tuple or list of two floats. \"\n",
    "            \"Received: %s\" % (brightness_range,)\n",
    "        )\n",
    "\n",
    "    u = np.random.uniform(brightness_range[0], brightness_range[1])\n",
    "    return apply_brightness_shift(x, u, scale)\n",
    "\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 - 0.5\n",
    "    o_y = float(y) / 2 - 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "\n",
    "@keras_export(\"keras.preprocessing.image.apply_affine_transform\")\n",
    "def apply_affine_transform(\n",
    "    x,\n",
    "    theta=0,\n",
    "    tx=0,\n",
    "    ty=0,\n",
    "    shear=0,\n",
    "    zx=1,\n",
    "    zy=1,\n",
    "    row_axis=1,\n",
    "    col_axis=2,\n",
    "    channel_axis=0,\n",
    "    fill_mode=\"nearest\",\n",
    "    cval=0.0,\n",
    "    order=1,\n",
    "):\n",
    "    \n",
    "    if scipy is None:\n",
    "        raise ImportError(\n",
    "            \"Image transformations require SciPy. \" \"Install SciPy.\"\n",
    "        )\n",
    "\n",
    "    # Input sanity checks:\n",
    "    # 1. x must 2D image with one or more channels (i.e., a 3D tensor)\n",
    "    # 2. channels must be either first or last dimension\n",
    "    if np.unique([row_axis, col_axis, channel_axis]).size != 3:\n",
    "        raise ValueError(\n",
    "            \"'row_axis', 'col_axis', and 'channel_axis'\" \" must be distinct\"\n",
    "        )\n",
    "\n",
    "    # shall we support negative indices?\n",
    "    valid_indices = set([0, 1, 2])\n",
    "    actual_indices = set([row_axis, col_axis, channel_axis])\n",
    "    if actual_indices != valid_indices:\n",
    "        raise ValueError(\n",
    "            f\"Invalid axis' indices: {actual_indices - valid_indices}\"\n",
    "        )\n",
    "\n",
    "    if x.ndim != 3:\n",
    "        raise ValueError(\"Input arrays must be multi-channel 2D images.\")\n",
    "    if channel_axis not in [0, 2]:\n",
    "        raise ValueError(\n",
    "            \"Channels are allowed and the first and last dimensions.\"\n",
    "        )\n",
    "\n",
    "    transform_matrix = None\n",
    "    if theta != 0:\n",
    "        theta = np.deg2rad(theta)\n",
    "        rotation_matrix = np.array(\n",
    "            [\n",
    "                [np.cos(theta), -np.sin(theta), 0],\n",
    "                [np.sin(theta), np.cos(theta), 0],\n",
    "                [0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        transform_matrix = rotation_matrix\n",
    "\n",
    "    if tx != 0 or ty != 0:\n",
    "        shift_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shift_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
    "\n",
    "    if shear != 0:\n",
    "        shear = np.deg2rad(shear)\n",
    "        shear_matrix = np.array(\n",
    "            [[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]]\n",
    "        )\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shear_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shear_matrix)\n",
    "\n",
    "    if zx != 1 or zy != 1:\n",
    "        zoom_matrix = np.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = zoom_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
    "\n",
    "    if transform_matrix is not None:\n",
    "        h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "        transform_matrix = transform_matrix_offset_center(\n",
    "            transform_matrix, h, w\n",
    "        )\n",
    "        x = np.rollaxis(x, channel_axis, 0)\n",
    "\n",
    "        # Matrix construction assumes that coordinates are x, y (in that order).\n",
    "        # However, regular numpy arrays use y,x (aka i,j) indexing.\n",
    "        # Possible solution is:\n",
    "        #   1. Swap the x and y axes.\n",
    "        #   2. Apply transform.\n",
    "        #   3. Swap the x and y axes again to restore image-like data ordering.\n",
    "        # Mathematically, it is equivalent to the following transformation:\n",
    "        # M' = PMP, where P is the permutation matrix, M is the original\n",
    "        # transformation matrix.\n",
    "        if col_axis > row_axis:\n",
    "            transform_matrix[:, [0, 1]] = transform_matrix[:, [1, 0]]\n",
    "            transform_matrix[[0, 1]] = transform_matrix[[1, 0]]\n",
    "        final_affine_matrix = transform_matrix[:2, :2]\n",
    "        final_offset = transform_matrix[:2, 2]\n",
    "\n",
    "        channel_images = [\n",
    "            ndimage.interpolation.affine_transform(\n",
    "                x_channel,\n",
    "                final_affine_matrix,\n",
    "                final_offset,\n",
    "                order=order,\n",
    "                mode=fill_mode,\n",
    "                cval=cval,\n",
    "            )\n",
    "            for x_channel in x\n",
    "        ]\n",
    "        x = np.stack(channel_images, axis=0)\n",
    "        x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def img_to_array():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a1b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd075f5d586f7218c0ec2ee7f78d4e38c753a8ee4d3182bef325db12ecbef5a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
